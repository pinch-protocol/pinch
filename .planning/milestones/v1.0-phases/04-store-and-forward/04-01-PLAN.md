---
phase: 04-store-and-forward
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - proto/pinch/v1/envelope.proto
  - gen/go/pinch/v1/envelope.pb.go
  - gen/ts/pinch/v1/envelope_pb.ts
  - relay/internal/store/db.go
  - relay/internal/store/blockstore.go
  - relay/internal/store/messagequeue.go
  - relay/internal/store/messagequeue_test.go
  - relay/internal/store/blockstore_test.go
  - relay/cmd/pinchd/main.go
autonomous: true
requirements:
  - RELY-05

must_haves:
  truths:
    - "MessageQueue can enqueue an encrypted envelope for an offline recipient and retrieve it in insertion order"
    - "MessageQueue enforces the 1,000 message per-agent cap and returns ErrQueueFull when exceeded"
    - "MessageQueue TTL sweep deletes expired messages and logs the count per agent"
    - "BlockStore and MessageQueue share a single bbolt database file without file lock conflicts"
  artifacts:
    - path: "proto/pinch/v1/envelope.proto"
      provides: "QueueStatus, QueueFull messages; was_stored field on DeliveryConfirm; MESSAGE_TYPE_QUEUE_STATUS and MESSAGE_TYPE_QUEUE_FULL enum values"
      contains: "QueueStatus"
    - path: "relay/internal/store/db.go"
      provides: "Shared bbolt database opener"
      exports: ["OpenDB"]
    - path: "relay/internal/store/messagequeue.go"
      provides: "Durable message queue with enqueue, flush, remove, count, sweep"
      exports: ["MessageQueue", "NewMessageQueue", "QueueEntry", "ErrQueueFull"]
    - path: "relay/internal/store/messagequeue_test.go"
      provides: "Unit tests for all MessageQueue operations"
      min_lines: 100
  key_links:
    - from: "relay/internal/store/db.go"
      to: "relay/internal/store/blockstore.go"
      via: "BlockStore receives shared *bolt.DB instead of opening its own"
      pattern: "func NewBlockStore\\(db \\*bolt\\.DB"
    - from: "relay/internal/store/db.go"
      to: "relay/internal/store/messagequeue.go"
      via: "MessageQueue receives shared *bolt.DB from OpenDB"
      pattern: "func NewMessageQueue\\(db \\*bolt\\.DB"
    - from: "relay/cmd/pinchd/main.go"
      to: "relay/internal/store/db.go"
      via: "main calls OpenDB once, passes DB to both stores"
      pattern: "store\\.OpenDB"
---

<objective>
Create the protobuf schema extensions for store-and-forward (QueueStatus, QueueFull, was_stored flag), extract a shared bbolt database opener, and implement the MessageQueue store with enqueue, batched flush, remove, count, and TTL sweep.

Purpose: Build the durable persistence layer that replaces the in-memory 30-second pending buffer with a 7-day TTL bbolt-backed message queue, including all the data-layer operations the hub integration (Plan 02) will need.

Output: Updated proto schema with generated Go/TS code, shared DB opener, fully tested MessageQueue store, refactored BlockStore accepting shared DB handle.
</objective>

<execution_context>
@/Users/riecekeck/.claude/get-shit-done/workflows/execute-plan.md
@/Users/riecekeck/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-store-and-forward/04-RESEARCH.md
@proto/pinch/v1/envelope.proto
@relay/internal/store/blockstore.go
@relay/internal/store/blockstore_test.go
@relay/cmd/pinchd/main.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Proto schema extensions and shared DB extraction</name>
  <files>
    proto/pinch/v1/envelope.proto
    gen/go/pinch/v1/envelope.pb.go
    gen/ts/pinch/v1/envelope_pb.ts
    relay/internal/store/db.go
    relay/internal/store/blockstore.go
    relay/internal/store/blockstore_test.go
    relay/cmd/pinchd/main.go
  </files>
  <action>
    **Part A: Proto schema changes**

    Add to `proto/pinch/v1/envelope.proto`:

    1. Add `bool was_stored = 5;` field to the `DeliveryConfirm` message (tells sender the message was queued and delivered later vs real-time).

    2. Add two new enum values to `MessageType`:
       - `MESSAGE_TYPE_QUEUE_STATUS = 13;`
       - `MESSAGE_TYPE_QUEUE_FULL = 14;`

    3. Add `QueueStatus` message:
       ```protobuf
       message QueueStatus {
           int32 pending_count = 1;
       }
       ```

    4. Add `QueueFull` message:
       ```protobuf
       message QueueFull {
           string recipient_address = 1;
           string reason = 2;
       }
       ```

    5. Add these to `Envelope`'s `oneof payload`:
       - `QueueStatus queue_status = 22;`
       - `QueueFull queue_full = 23;`

    Run `npx buf generate` from the workspace root to regenerate Go and TypeScript code.
    Verify the generated files include the new types.

    **Part B: Shared DB extraction**

    Create `relay/internal/store/db.go`:
    - `func OpenDB(path string) (*bolt.DB, error)` that calls `bolt.Open(path, 0600, nil)` and returns the handle.
    - This is the ONLY place in the codebase that opens a bbolt file. Both BlockStore and MessageQueue receive the shared `*bolt.DB`.

    Refactor `relay/internal/store/blockstore.go`:
    - Change `NewBlockStore(path string)` to `NewBlockStore(db *bolt.DB)`.
    - Remove the `bolt.Open()` call from NewBlockStore.
    - Keep the `Close()` method but have it be a no-op or remove it (the shared DB handle is closed by the caller). Recommendation: remove `Close()` from BlockStore since it no longer owns the DB. The caller (main.go) closes the DB.

    Update `relay/internal/store/blockstore_test.go`:
    - `newTestBlockStore` should call `store.OpenDB(path)` first, then `store.NewBlockStore(db)`. The test cleanup closes the DB.
    - The `TestPersistenceAcrossReopen` test needs to close the DB and reopen with `OpenDB` + `NewBlockStore`.

    Update `relay/cmd/pinchd/main.go`:
    - Replace `store.NewBlockStore(dbPath)` with `store.OpenDB(dbPath)` then `store.NewBlockStore(db)`.
    - `defer db.Close()` instead of `defer blockStore.Close()`.
    - Instantiate `store.NewMessageQueue(db, ...)` (will be used in Plan 02, but create the instance here so it compiles).
    - Pass the messageQueue to `hub.NewHub(blockStore, messageQueue)` -- but since Plan 02 changes the Hub, for now just create the MessageQueue and log that it's ready. The Hub signature change happens in Plan 02.

    NOTE: Since the Hub signature change happens in Plan 02, temporarily create the MessageQueue in main.go but don't pass it to NewHub yet. Just assign to a variable so it's used (avoid unused variable error). A simple `_ = mq` or a log statement works.
  </action>
  <verify>
    <automated>cd /Users/riecekeck/Coding/Pinch && npx buf generate && go test ./relay/internal/store/... -v -count=1 2>&1 | tail -20</automated>
    <manual>Check that gen/go/pinch/v1/envelope.pb.go contains QueueStatus and QueueFull types, and DeliveryConfirm has WasStored field</manual>
  </verify>
  <done>
    Proto schema has QueueStatus, QueueFull, was_stored on DeliveryConfirm, and two new MessageType values.
    Generated Go and TS code includes new types.
    BlockStore accepts *bolt.DB instead of path.
    db.go provides shared OpenDB.
    BlockStore tests pass with shared DB pattern.
    main.go uses OpenDB for shared handle.
  </done>
</task>

<task type="auto">
  <name>Task 2: MessageQueue store implementation with unit tests</name>
  <files>
    relay/internal/store/messagequeue.go
    relay/internal/store/messagequeue_test.go
  </files>
  <action>
    Create `relay/internal/store/messagequeue.go`:

    **Types:**
    - `ErrQueueFull` sentinel error: `errors.New("message queue: recipient queue is full")`
    - `QueueEntry` struct: `Key []byte`, `Envelope []byte`, `SenderAddr string`
    - `queuedMessage` struct (unexported): `EnqueuedAt int64` (Unix nanos), `SenderAddr string`, `Envelope []byte` (raw serialized protobuf)
    - `MessageQueue` struct: `db *bolt.DB`, `maxPerAgent int`, `ttl time.Duration`, `sweepInterval time.Duration`

    **Bucket structure:**
    - Top-level bucket: `[]byte("queue")`
    - Per-recipient nested buckets: keyed by recipient address string
    - Message keys: 16-byte `[8-byte big-endian nanosecond timestamp][8-byte big-endian sequence]` for lexicographic ordering

    **Functions:**

    `NewMessageQueue(db *bolt.DB, maxPerAgent int, ttl time.Duration) (*MessageQueue, error)`:
    - Creates the top-level "queue" bucket if not exists
    - Stores maxPerAgent and ttl
    - Default sweep interval: 5 minutes (hardcoded, per Claude's discretion)
    - Returns the MessageQueue

    `encodeKey(timestampNanos int64, seq uint64) []byte` (unexported):
    - Returns 16-byte key with big-endian encoding for both values

    `Enqueue(recipientAddr, senderAddr string, envelope []byte) error`:
    - Opens an Update transaction
    - Gets or creates the per-recipient nested bucket
    - Checks `sub.Stats().KeyN >= mq.maxPerAgent` -- if so, return `ErrQueueFull`
    - Generates ordered key using `time.Now().UnixNano()` and `sub.NextSequence()`
    - JSON-marshals `queuedMessage{EnqueuedAt: now, SenderAddr: senderAddr, Envelope: envelope}`
    - Puts key/value into the nested bucket

    `FlushBatch(recipientAddr string, batchSize int) ([]QueueEntry, error)`:
    - Read-only View transaction
    - Opens per-recipient nested bucket (returns empty if nil)
    - Cursor iterates from First(), collects up to batchSize entries
    - Skips expired messages (don't delete here -- sweep handles that)
    - Copies key bytes (not valid after tx) into QueueEntry
    - Returns entries in order

    `Remove(recipientAddr string, key []byte) error`:
    - Update transaction, deletes the specific key from the per-recipient bucket
    - No-op if bucket or key doesn't exist

    `Count(recipientAddr string) int`:
    - Read-only View transaction
    - Returns `sub.Stats().KeyN` for the per-recipient bucket (0 if bucket doesn't exist)

    `Sweep() (int, error)`:
    - Single Update transaction
    - Iterates all nested buckets (each is a recipient address)
    - For each bucket: two-pass collect-then-delete for expired messages (avoid cursor skip bug)
    - A message is expired if `time.Now().UnixNano() - msg.EnqueuedAt > mq.ttl.Nanoseconds()`
    - Logs per-agent cleaned count using slog.Info: `"Cleaned N expired messages for <address>"`
    - Returns total count of cleaned messages

    `StartSweep(ctx context.Context)`:
    - Goroutine with `time.NewTicker(mq.sweepInterval)` (5 minutes)
    - On each tick, calls `Sweep()`
    - Stops when ctx is cancelled

    **Value encoding:** Use `encoding/json` for queuedMessage (human-debuggable, small values, write path already serialized by bbolt).

    **Error handling for corrupt entries:** In FlushBatch, if json.Unmarshal fails, skip the entry and log a warning with slog.Warn. Do NOT delete corrupt entries in FlushBatch -- let sweep handle them or leave for manual inspection.

    Create `relay/internal/store/messagequeue_test.go`:

    Tests (all use `store.OpenDB(tempPath)` + `store.NewMessageQueue(db, ...)`):

    1. `TestEnqueueAndFlushBatch`: Enqueue 3 messages, FlushBatch with batchSize=10, verify all 3 returned in order.
    2. `TestEnqueueQueueFull`: Set maxPerAgent=5, enqueue 5 messages, verify 6th returns ErrQueueFull.
    3. `TestFlushBatchOrdering`: Enqueue messages with small time.Sleep between them, verify FlushBatch returns them in chronological order.
    4. `TestFlushBatchBatching`: Enqueue 10 messages, FlushBatch with batchSize=3, verify only 3 returned. Call again, verify next 3.
    5. `TestRemove`: Enqueue 3, flush to get keys, remove middle one, flush again -- verify only 2 remain.
    6. `TestCount`: Enqueue N messages, verify Count returns N. Remove one, verify Count returns N-1.
    7. `TestSweep`: Enqueue with very short TTL (1ms), sleep briefly, call Sweep(), verify Count is 0.
    8. `TestSweepLeavesUnexpired`: Enqueue with long TTL (1 hour), call Sweep(), verify Count unchanged.
    9. `TestFlushBatchSkipsExpired`: Enqueue with very short TTL, sleep, FlushBatch returns 0 entries (skips expired without deleting).
    10. `TestEmptyFlush`: FlushBatch on non-existent address returns empty slice, no error.
    11. `TestMultipleRecipients`: Enqueue messages for 2 different addresses, FlushBatch for each returns only their messages.
    12. `TestSharedDBWithBlockStore`: Open DB, create both BlockStore and MessageQueue, verify both work without conflict.

    Use `testing.Short()` skip for the sleep-dependent TTL tests if they take too long.
  </action>
  <verify>
    <automated>cd /Users/riecekeck/Coding/Pinch && go test ./relay/internal/store/... -v -count=1 -run TestEnqueue -run TestFlush -run TestRemove -run TestCount -run TestSweep -run TestEmpty -run TestMultiple -run TestShared 2>&1 | tail -30</automated>
    <manual>Verify messagequeue.go exports MessageQueue, NewMessageQueue, QueueEntry, ErrQueueFull, and all test functions pass</manual>
  </verify>
  <done>
    MessageQueue store implements Enqueue, FlushBatch, Remove, Count, Sweep, StartSweep.
    1,000-message per-agent cap enforced with ErrQueueFull.
    TTL sweep uses two-pass collect-then-delete to avoid cursor skip bug.
    Sweep logs "Cleaned N expired messages for <address>" per agent.
    All 12 unit tests pass including shared DB coexistence with BlockStore.
    JSON encoding for human-debuggable queue values.
  </done>
</task>

</tasks>

<verification>
1. `npx buf generate` succeeds and generates updated Go/TS protobuf code
2. `go build ./relay/...` compiles successfully with shared DB pattern
3. `go test ./relay/internal/store/... -v -count=1` -- all BlockStore AND MessageQueue tests pass
4. `grep -r "QueueStatus" gen/go/pinch/v1/envelope.pb.go` confirms new proto types exist
5. `grep -r "was_stored" gen/ts/pinch/v1/envelope_pb.ts` confirms TypeScript types updated
</verification>

<success_criteria>
- Proto schema has QueueStatus, QueueFull, was_stored, and two new MessageType enum values
- Generated Go and TypeScript code includes all new types
- OpenDB provides shared bbolt handle; BlockStore and MessageQueue both accept *bolt.DB
- MessageQueue passes all unit tests: enqueue, flush ordering, batching, remove, count, sweep, queue cap, shared DB
- main.go compiles with shared DB pattern creating both stores
</success_criteria>

<output>
After completion, create `.planning/phases/04-store-and-forward/04-01-SUMMARY.md`
</output>
