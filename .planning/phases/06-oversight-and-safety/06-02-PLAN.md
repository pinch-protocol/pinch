---
phase: 06-oversight-and-safety
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - proto/pinch/v1/envelope.proto
  - gen/go/pinch/v1/envelope.pb.go
  - gen/ts/pinch/v1/envelope_pb.ts
  - relay/internal/hub/ratelimit.go
  - relay/internal/hub/ratelimit_test.go
  - relay/internal/hub/hub.go
  - relay/cmd/pinchd/main.go
  - skill/src/message-manager.ts
autonomous: true
requirements:
  - RELY-07

must_haves:
  truths:
    - "Relay enforces per-connection rate limiting using a token bucket algorithm"
    - "When rate-limited, the sender receives a RateLimited error with retry_after_ms duration"
    - "Rate limiters are cleaned up when clients disconnect (no memory leak)"
    - "TypeScript skill handles the RateLimited message type gracefully"
  artifacts:
    - path: "relay/internal/hub/ratelimit.go"
      provides: "Per-connection token bucket rate limiter"
      contains: "RateLimiter"
    - path: "proto/pinch/v1/envelope.proto"
      provides: "MESSAGE_TYPE_RATE_LIMITED enum and RateLimited message"
      contains: "MESSAGE_TYPE_RATE_LIMITED"
  key_links:
    - from: "relay/internal/hub/hub.go"
      to: "relay/internal/hub/ratelimit.go"
      via: "rateLimiter.Allow() check in RouteMessage"
      pattern: "rateLimiter.*Allow"
    - from: "relay/internal/hub/hub.go"
      to: "proto envelope"
      via: "sendRateLimited builds RateLimited envelope"
      pattern: "sendRateLimited"
---

<objective>
Add relay-side per-connection rate limiting using Go's `golang.org/x/time/rate` token bucket and extend the protobuf schema with a RateLimited error message.

Purpose: Protects the relay against message flooding (RELY-07). Generous defaults allow normal chatty agents but reject obvious abuse. Senders receive actionable feedback (retry-after duration) rather than silent drops.

Output: `ratelimit.go` with per-connection token bucket, proto schema with `RateLimited` message type, hub integration, TypeScript handling, passing tests.
</objective>

<execution_context>
@/Users/riecekeck/.claude/get-shit-done/workflows/execute-plan.md
@/Users/riecekeck/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-oversight-and-safety/06-CONTEXT.md
@.planning/phases/06-oversight-and-safety/06-RESEARCH.md
@proto/pinch/v1/envelope.proto
@relay/internal/hub/hub.go
@relay/internal/hub/client.go
@relay/cmd/pinchd/main.go
@skill/src/message-manager.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Proto schema extension and Go rate limiter with hub integration</name>
  <files>
    proto/pinch/v1/envelope.proto
    relay/internal/hub/ratelimit.go
    relay/internal/hub/ratelimit_test.go
    relay/internal/hub/hub.go
    relay/cmd/pinchd/main.go
  </files>
  <action>
**Step 1: Extend protobuf schema** in `proto/pinch/v1/envelope.proto`:

Add to `MessageType` enum:
```protobuf
MESSAGE_TYPE_RATE_LIMITED = 15;
```

Add new message type:
```protobuf
// RateLimited is sent to the sender when their messages exceed the
// per-connection rate limit. Contains retry-after information.
message RateLimited {
  int64 retry_after_ms = 1;  // milliseconds until sender can retry
  string reason = 2;          // human-readable explanation
}
```

Add to `Envelope` oneof payload:
```protobuf
RateLimited rate_limited = 24;
```

Run `buf generate` from the repo root to regenerate Go and TypeScript code:
```bash
cd /Users/riecekeck/Coding/Pinch && buf generate
```

**Step 2: Create `relay/internal/hub/ratelimit.go`:**

```go
package hub

import (
    "sync"
    "golang.org/x/time/rate"
)

// RateLimiter manages per-connection token bucket rate limiters.
// Each pinch address gets its own limiter created on first message.
type RateLimiter struct {
    mu       sync.Mutex
    limiters map[string]*rate.Limiter
    rate     rate.Limit
    burst    int
}

// NewRateLimiter creates a rate limiter with the given sustained rate
// and burst size. Recommended defaults: rate=1.0 (60 msgs/min), burst=10.
func NewRateLimiter(r rate.Limit, burst int) *RateLimiter { ... }

// Allow checks if the given address is under the rate limit.
// Returns true if allowed, false if rate-limited.
func (rl *RateLimiter) Allow(address string) bool { ... }

// Remove deletes the limiter for the given address.
// Call on client disconnect to prevent memory leaks.
func (rl *RateLimiter) Remove(address string) { ... }
```

Use `golang.org/x/time/rate.NewLimiter(r, burst)` for each address. Create limiter lazily on first `Allow()` call. Use `sync.Mutex` (not RWMutex -- short critical section with lazy creation needs write lock anyway).

Default values (Claude's discretion per CONTEXT.md):
- Rate: `rate.Limit(1.0)` = 1 token/second = 60 messages/minute sustained
- Burst: 10 -- allows short bursts of rapid messages

**Step 3: Create `relay/internal/hub/ratelimit_test.go`:**
- Test `Allow()` returns true for first message
- Test `Allow()` returns false after burst is exhausted (call burst+1 times rapidly)
- Test `Remove()` cleans up the limiter (call Remove, then Allow creates fresh limiter with full burst)
- Test concurrent access safety (multiple goroutines calling Allow)

**Step 4: Integrate rate limiter in `hub.go`:**

Add `rateLimiter *RateLimiter` field to `Hub` struct. Update `NewHub` to accept it:
```go
func NewHub(blockStore *store.BlockStore, mq *store.MessageQueue, rl *RateLimiter) *Hub
```

In `RouteMessage()`, add rate limit check as the FIRST step (before envelope size check):
```go
if h.rateLimiter != nil && !h.rateLimiter.Allow(from.Address()) {
    h.sendRateLimited(from)
    return nil
}
```

Add `sendRateLimited(client *Client)` method that builds and sends a `RateLimited` envelope with `retry_after_ms = 1000` (1 second) and a human-readable reason.

In the `unregister` case of `Run()`, call `h.rateLimiter.Remove(client.address)` to clean up the limiter on disconnect.

**Step 5: Update `relay/cmd/pinchd/main.go`:**

Add env var parsing for rate limit config:
- `PINCH_RELAY_RATE_LIMIT` -- messages per second (float, default: 1.0)
- `PINCH_RELAY_RATE_BURST` -- burst size (int, default: 10)

Create `hub.NewRateLimiter(rateLimit, rateBurst)` and pass to `hub.NewHub(blockStore, mq, rl)`.

**Step 6: Install Go dependency:**
```bash
cd /Users/riecekeck/Coding/Pinch/relay && go get golang.org/x/time/rate
```

**Important:** Update ALL callers of `NewHub` -- check `hub_test.go` for test calls to `NewHub` that need the new `rl` parameter. Pass `nil` for rate limiter in existing tests that don't test rate limiting.
  </action>
  <verify>
    <automated>cd /Users/riecekeck/Coding/Pinch/relay && go test ./internal/hub/ -run TestRateLimiter -v -count=1 && go test ./internal/hub/ -count=1 && go vet ./...</automated>
  </verify>
  <done>Rate limiter enforces per-connection token bucket at relay. RateLimited proto message defined. Hub rejects messages exceeding rate limit and sends actionable error. Limiter cleaned up on disconnect. Existing hub tests pass with nil rate limiter.</done>
</task>

<task type="auto">
  <name>Task 2: TypeScript handling of RateLimited message type</name>
  <files>
    skill/src/message-manager.ts
  </files>
  <action>
Update `skill/src/message-manager.ts` to handle the new `MESSAGE_TYPE_RATE_LIMITED` envelope:

1. **Add RateLimited handler in `setupHandlers()`:**
   In the `onEnvelope` switch statement, add a case for `MessageType.RATE_LIMITED`:
   ```typescript
   case MessageType.RATE_LIMITED:
     this.handleRateLimited(envelope);
     break;
   ```

2. **Add `handleRateLimited` private method:**
   ```typescript
   private handleRateLimited(envelope: Envelope): void {
     if (envelope.payload.case !== "rateLimited") return;
     const { retryAfterMs, reason } = envelope.payload.value;
     console.warn(
       `Rate limited by relay: ${reason}. Retry after ${retryAfterMs}ms`
     );
   }
   ```

   This is a minimal handler -- logs the rate limit signal. Future enhancement could add automatic backoff, but for v1 logging is sufficient per the user's "generous defaults" decision (rate limits should only hit during obvious abuse).

3. **Verify the generated TypeScript code** from `buf generate` includes `RATE_LIMITED` in the `MessageType` enum and `RateLimited` message type. If the enum value name differs from `RATE_LIMITED` in the generated code, use the correct enum member name.

Note: The `MessageType` import in message-manager.ts already exists. The `RateLimited` message type will be available from the generated proto code after `buf generate` ran in Task 1.
  </action>
  <verify>
    <automated>cd /Users/riecekeck/Coding/Pinch && npx vitest run skill/src/tools/pinch-send.test.ts && npx tsc --noEmit -p skill/tsconfig.json 2>/dev/null || echo "Type check: verify manually if tsconfig not present"</automated>
  </verify>
  <done>TypeScript MessageManager handles RateLimited envelopes from the relay. Rate limit signal logged with retry-after duration. No regression in existing send tests.</done>
</task>

</tasks>

<verification>
1. `buf generate` succeeds -- proto compiles cleanly
2. Go rate limiter tests pass with concurrent access safety
3. All existing hub tests pass (nil rate limiter backward compatible)
4. Relay builds and starts with rate limiting enabled
5. TypeScript compiles with new proto types
6. `go test ./...` from relay/ passes
</verification>

<success_criteria>
- Protobuf schema includes MESSAGE_TYPE_RATE_LIMITED and RateLimited message
- Go rate limiter enforces per-connection token bucket (1 msg/s sustained, burst 10)
- Rate-limited senders receive RateLimited envelope with retry_after_ms
- Limiter entries cleaned up on client disconnect
- TypeScript handles RateLimited messages gracefully
- Configurable via PINCH_RELAY_RATE_LIMIT and PINCH_RELAY_RATE_BURST env vars
</success_criteria>

<output>
After completion, create `.planning/phases/06-oversight-and-safety/06-02-SUMMARY.md`
</output>
